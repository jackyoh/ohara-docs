---
title: Worker
linktitle: Worker API
toc: true
type: docs
date: "2020-06-18T00:00:00+01:00"
draft: false
menu:
  011x:
    parent: REST APIs
    weight: 190
---

[Worker](https://kafka.apache.org/intro) is core of running connectors
for Ohara. It provides a simple but powerful system to distribute and
execute connectors on different nodes. The performance of connectors
depends on the scale of worker cluster. For example, you can assign the
number of task when creating connector. If there is only 3 nodes within
your worker cluster and you specify 6 tasks for your connector, the
tasks of you connectors still be deployed on 3 nodes. That is to say,
the connector can't get more resources to execute.

Worker is based on [Broker]({{< relref "./brokers.md" >}}), 
hence you have to create broker cluster first. Noted that a
broker cluster can be used by multi worker clusters. BTW, worker cluster
will pre-allocate a lot of topics on broker cluster, and the pre-created
topics CAN'T be reused by different worker clusters.

The properties which can be set by user are shown below.

1. name (**string**) --- cluster name. The legal character is number,
   lowercase alphanumeric characters, or '.'
2. group (**string**) --- cluster group. The legal character is number,
   lowercase alphanumeric characters, or '.'
3. imageName (**string**) --- docker image
4. brokerClusterKey (**Object**) --- the broker cluster used to store
   data generated by this worker cluster
   - brokerClusterKey.group (**option(string)**) --- the group of
     cluster
   - brokerClusterKey.name (**string**) --- the name of cluster
{{% alert note %}}
the following forms are legal as well: (1) `{"name": "n"}`, (2) `"n"`.
Both forms are converted to `{"group": "default", "name": "n"}`
{{% /alert %}}
5. clientPort (**int**) --- worker client port
6. jmxPort (**int**) --- worker jmx port
7. freePorts (**Array(int)**) --- the ports you want to pre-bind for the connectors.

   If your connectors want to build a service on a port which is available 
   to external nodes, you have to define the free ports for your worker cluster
   so as to make Configurator pre-bind the ports on your worker
   cluster. Otherwise, your connectors is disable to build service
   on the port of worker cluster and be connected by external node.
   
8. group.id (**string**) --- the id of worker stored in broker cluster
9. config.storage.topic (**string**) --- a internal topic used to store
   connector configuration
10. config.storage.replication.factor (**int**) --- number of
    replications for config topic
11. offset.storage.topic (**string**) --- a internal topic used to store
    connector offset
12. offset.storage.partitions (**int**) --- number of partitions for
    offset topic
13. offset.storage.replication.factor (**int**) --- number of
    replications for offset topic
14. status.storage.topic (**string**) --- an internal topic used to store
    connector status
15. status.storage.partitions (**int**) --- number of partitions for
    status topic
16. status.storage.replication.factor (**int**) --- number of
    replications for status topic
17. pluginKeys (**array(object)**) --- the "primary key" of jars which contain your connectors

    You can require worker cluster to load the jars stored in ohara
    if you want to run custom connectors on the worker cluster. see
    [Files APIs]({{< relref "./files.md" >}}) for
    uploading jars to ohara. The files which are deployed to worker
    must be uber jars - it must include all dependencies exclude for
    ohara stuff.

18. sharedJarKeys (**array(object)**) --- those jars is deployed on the root classpath so
    all connectors are able to load them.

{{% alert hint %}}
1. When you implement the Ohara connector, you must use the
 File API upload connector jar file to worker.

2.  If your jdbc source connector need to use the third party
  jar file (such oracle jdbc jar file), you must use the File
  API upload jar file then setting sharedJarKeys to create the
  worker API.
{{% /alert %}}

19. nodeNames (**array(string)**) --- the nodes running the worker
    process

    The following information are updated by Ohara.
20. aliveNodes (**array(string)**) --- the nodes that host the running
    containers of worker

{{% alert hint %}}
The group.id, config.storage.topic, offset.storage.topic and
status.storage.topic must be unique in broker cluster. Don't reuse
them in same broker cluster. Dispatching above unique resources to
two worker cluster will pollute the data. Of course, Ohara do a
quick failure for this dumb case. However, it is not a quick
failure when you are using raw kafka rather than Ohara. Please
double check what you configure!
{{% /alert %}}

## create a worker properties {#rest-workers-create}

*POST /v0/workers*

* Example Request
    ```json
    {
      "name": "wk",
      "nodeNames": ["node00"],
      "brokerClusterKey": "bk"
    }
    ```

* Example Response
    ```json
    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982566359,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:{{< ohara-version >}}",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 33333,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }
    ```

## list all workers clusters {#rest-workers-list}

*GET /v0/workers*

* Example Response
    ```json
    [
      {
        "brokerClusterKey": {
          "group": "default",
          "name": "bk00"
        },
        "name": "wk00",
        "offset.storage.partitions": 1,
        "xms": 2048,
        "routes": {},
        "config.storage.topic": "b8dadc3de21048fa927335b8f",
        "sharedJarKeys": [],
        "lastModified": 1578982566359,
        "tags": {},
        "xmx": 2048,
        "imageName": "oharastream/connect-worker:{{< ohara-version >}}",
        "offset.storage.topic": "346b839ea3e74387ab1eea409",
        "status.storage.replication.factor": 1,
        "group.id": "af4b4d49234a4848bb90fb452",
        "offset.storage.replication.factor": 1,
        "aliveNodes": [],
        "pluginKeys": [],
        "status.storage.partitions": 1,
        "freePorts": [],
        "jmxPort": 33333,
        "config.storage.partitions": 1,
        "clientPort": 45127,
        "config.storage.replication.factor": 1,
        "group": "default",
        "nodeNames": [
          "node00"
        ],
        "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
      }
    ]
    ```

## update broker cluster properties

*PUT /v0/workers/$name?group=$group*

{{% alert hint %}}
If the required worker (group, name) was not exists, we will try to use
this request as POST
{{% /alert %}}

* Example Request
    ```json
    {
      "jmxPort": 7777
    }
    ```

* Example Response
    ```json
    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982765738,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:{{< ohara-version >}}",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 7777,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }
    ```

## delete a worker properties

*DELETE /v0/workers/$name?group=$group*

You cannot delete properties of an non-stopped worker cluster. We will
use the default value as the query parameter "?group=" if you don't
specify it.

* Example Response
    ````
    204 NoContent
    ````

{{% alert hint %}}
It is ok to delete an nonexistent worker cluster, and the response
is 204 NoContent.
{{% /alert %}}

## get a worker cluster {#rest-workers-get}

*GET /v0/workers/$name?group=$group*

We will use the default value as the query parameter "?group=" if you
don't specify it.

* Example Response
    ```json
    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982765738,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:{{< ohara-version >}}",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 7777,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }
    ```

## start a worker cluster

*PUT /v0/workers/$name/start?group=$group*

We will use the default value as the query parameter "?group=" if you
don't specify it.

* Example Response
    ```
    202 Accepted
    ```

{{% alert hint %}}
You should use [Get worker cluster]({{< relref "#rest-workers-get" >}}) to fetch up-to-date status
{{% /alert %}}

## stop a worker cluster

Gracefully stopping a running worker cluster.

*PUT /v0/workers/$name/stop?group=$group[&force=true]*

We will use the default value as the query parameter "?group=" if you
don't specify it.

* Query Parameters
  1. force (**boolean**) --- true if you don't want to wait the
     graceful shutdown (it can save your time but may damage your
     data).

* Example Response
    ```
    202 Accepted
    ```

{{% alert hint %}}
You should use [Get worker cluster]({{< relref "#rest-workers-get" >}}) to fetch up-to-date status
{{% /alert %}}

## add a new node to a running worker cluster

*PUT /v0/workers/$name/$nodeName?group=$group*

We will use the default value as the query parameter "?group=" if you
don't specify it.

If you want to extend a running worker cluster, you can add a node to
share the heavy loading of a running worker cluster. However, the
balance is not triggered at once. By the way, moving a task to another
idle node needs to **stop** task first. Don't worry about the temporary
lower throughput when balancer is running.

## remove a node from a running worker cluster

*DELETE /v0/workers/$name/$nodeName?group=$group*

We will use the default value as the query parameter "?group=" if you
don't specify it.

If your budget is limited, you can decrease the number of nodes running
worker cluster. BUT, removing a node from a running worker cluster
invoke a lot of task move, and it will decrease the throughput of your
connector.

* Example Response
    ```
    204 NoContent
    ```

{{% alert hint %}}
It is ok to delete an nonexistent worker node, and the response is
204 NoContent.
{{% /alert %}}
